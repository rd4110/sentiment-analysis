# -*- coding: utf-8 -*-
"""loan_eligibility_prediction2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nlQM-UHaMsDN4Z7QWm01FypugLri5zge
"""

!pip install pandas numpy scikit-learn matplotlib seaborn



import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.ensemble import VotingClassifier

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()

# Load the training and testing datasets
train_data = pd.read_csv('loan-train.csv')
test_data = pd.read_csv('loan-test.csv')

# Separate features and target variable in the training data
X_train = train_data.drop(columns=['Loan_Status', 'Loan_ID'])  # Drop Loan_ID as well
y_train = train_data['Loan_Status'].map({'Y': 1, 'N': 0})  # Convert target to binary

# Separate features and Loan_ID in the test data (since Loan_Status isn't available in test)
X_test = test_data.drop(columns=['Loan_ID'])

# Handling missing values (simplified)
numeric_cols = X_train.select_dtypes(include=[np.number]).columns
categorical_cols = X_train.select_dtypes(exclude=[np.number]).columns

X_train[numeric_cols] = X_train[numeric_cols].fillna(X_train[numeric_cols].mean())
X_test[numeric_cols] = X_test[numeric_cols].fillna(X_test[numeric_cols].mean())

X_train[categorical_cols] = X_train[categorical_cols].fillna(X_train[categorical_cols].mode().iloc[0])
X_test[categorical_cols] = X_test[categorical_cols].fillna(X_test[categorical_cols].mode().iloc[0])

# Encode categorical variables
X_train = pd.get_dummies(X_train, drop_first=True)
X_test = pd.get_dummies(X_test, drop_first=True)

# Ensure that the training and test sets have the same columns
X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)

# Standardize the features (useful for Logistic Regression)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Proceed with model training and evaluation as before
# Train Logistic Regression model
logreg = LogisticRegression(random_state=42)
logreg.fit(X_train, y_train)

# Train Random Forest model
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)

# Create and train the Hybrid Model
hybrid_model = VotingClassifier(estimators=[
    ('logreg', logreg),
    ('rf', rf)
], voting='soft')

hybrid_model.fit(X_train, y_train)

# Evaluate the models
y_pred_logreg = logreg.predict(X_train)
y_pred_rf = rf.predict(X_train)
y_pred_hybrid = hybrid_model.predict(X_train)

# Function to evaluate model performance
def evaluate_model(y_true, y_pred):
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    roc_auc = roc_auc_score(y_true, y_pred)
    return accuracy, precision, recall, f1, roc_auc

# Evaluate each model
logreg_results = evaluate_model(y_train, y_pred_logreg)
rf_results = evaluate_model(y_train, y_pred_rf)
hybrid_results = evaluate_model(y_train, y_pred_hybrid)

# Print results
results_df = pd.DataFrame({
    'Model': ['Logistic Regression', 'Random Forest', 'Hybrid Model'],
    'Accuracy': [logreg_results[0], rf_results[0], hybrid_results[0]],
    'Precision': [logreg_results[1], rf_results[1], hybrid_results[1]],
    'Recall': [logreg_results[2], rf_results[2], hybrid_results[2]],
    'F1 Score': [logreg_results[3], rf_results[3], hybrid_results[3]],
    'ROC AUC': [logreg_results[4], rf_results[4], hybrid_results[4]]
})

print(results_df)

"""Descriptive statisticsðŸ“Œ"""

print(f"Total number of records in the dataset: {df.shape[0]}")

df = pd.read_csv('loan-train.csv')

print(f"Data before preprocessing: {df.shape[0]}")
# Apply preprocessing steps
print(f"Data after preprocessing: {df.shape[0]}")

print(df['Education'].value_counts(dropna=False))

print(df['Education'].isnull().sum())  # Number of missing values
print(df['Education'].unique())  # Unique values

print(df.shape)

print(df.head())  # Check the first few rows
print(df.tail())  # Check the last few rows

education_distribution = df['Education'].value_counts()
print(education_distribution)

print(df['Education'].describe())  # Summary statistics

import pandas as pd

# Load the dataset
train_data = pd.read_csv('loan-train.csv')

# Calculate descriptive statistics for numeric features
numeric_features = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']

# Summary statistics
summary_stats = train_data[numeric_features].describe()

# Additional statistics: variance and mode
variance = train_data[numeric_features].var()
mode = train_data[numeric_features].mode().iloc[0]  # Mode returns a DataFrame; .iloc[0] to get the first row as a Series

print("Summary Statistics:")
print(summary_stats)
print("\nVariance:")
print(variance)
print("\nMode:")
print(mode)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
train_data = pd.read_csv('loan-train.csv')

# Numeric features
numeric_features = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term']

# Plot histograms
plt.figure(figsize=(14, 10))
for i, feature in enumerate(numeric_features, 1):
    plt.subplot(2, 2, i)
    sns.histplot(train_data[feature], kde=True)
    plt.title(f'Histogram of {feature}')
    plt.xlabel(feature)
    plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

# Box plots
plt.figure(figsize=(14, 10))
for i, feature in enumerate(numeric_features, 1):
    plt.subplot(2, 2, i)
    sns.boxplot(y=train_data[feature])
    plt.title(f'Box Plot of {feature}')
    plt.ylabel(feature)

plt.tight_layout()
plt.show()

# Categorical features
categorical_features = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area', 'Loan_Status']

# Distribution of categorical features
categorical_distribution = {feature: train_data[feature].value_counts() for feature in categorical_features}

print("Categorical Distributions:")
for feature, distribution in categorical_distribution.items():
    print(f"\n{feature}:")
    print(distribution)

# Categorical features
categorical_features = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area', 'Loan_Status']

# Plot bar charts
plt.figure(figsize=(14, 18))
for i, feature in enumerate(categorical_features, 1):
    plt.subplot(4, 2, i)
    sns.countplot(x=train_data[feature])
    plt.title(f'Distribution of {feature}')
    plt.xlabel(feature)
    plt.ylabel('Count')

plt.tight_layout()
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Load the dataset
train_data = pd.read_csv('loan-train.csv')

# Encode categorical variables using one-hot encoding
encoded_data = pd.get_dummies(train_data, drop_first=True)

# Display the first few rows of the encoded data to check
print(encoded_data.head())

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from google.colab import files
uploaded = files.upload()

# Load the data
df = pd.read_csv('loan-train.csv')

# Display basic information about the dataset
print(df.info())

# Select numerical columns for correlation analysis
numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns

# Calculate the correlation matrix
correlation_matrix = df[numeric_columns].corr()

# Create a heatmap of the correlation matrix
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0)
plt.title('Correlation Heatmap of Numerical Variables')
plt.tight_layout()
plt.savefig('correlation_heatmap.png')
plt.close()

print("Correlation matrix:")
print(correlation_matrix)

# Display the heatmap
from IPython.display import Image
Image('correlation_heatmap.png')

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import numpy as np
from google.colab import files
uploaded = files.upload()

# Load the data
df = pd.read_csv('loan-train.csv')

# Fill missing values with the median for numerical columns and mode for categorical columns
df.fillna(df.median(numeric_only=True), inplace=True)
for column in df.select_dtypes(include=['object']).columns:
    df[column].fillna(df[column].mode()[0], inplace=True)

# Encode categorical variables
label_encoders = {}
for column in df.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    df[column] = le.fit_transform(df[column])
    label_encoders[column] = le

# Define features and target variable
X = df.drop(['Loan_ID', 'Loan_Status'], axis=1)
y = df['Loan_Status']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Random Forest model
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)

# Get feature importances
feature_importances = rf.feature_importances_

# Create a DataFrame for feature importances
feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})
feature_importance_df.sort_values(by='Importance', ascending=False, inplace=True)

# Plot feature importances
plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance_df)
plt.title('Feature Importance')
plt.tight_layout()
plt.savefig('feature_importance.png')
plt.close()

print("Feature importance analysis completed.")
print(feature_importance_df)

# Display the feature importance plot
from IPython.display import Image
Image('feature_importance.png')

from sklearn.model_selection import cross_val_score
from scipy.stats import chi2_contingency
from statsmodels.stats.outliers_influence import variance_inflation_factor
import statsmodels.api as sm
from google.colab import files
uploaded = files.upload()
# 1. Statistical Hypothesis Testing
# Example: Chi-square test for independence between 'Credit_History' and 'Loan_Status'
contingency_table = pd.crosstab(df['Credit_History'], df['Loan_Status'])
chi2, p, dof, expected = chi2_contingency(contingency_table)

# 2. Model Assumptions Validation
# Check for multicollinearity using Variance Inflation Factor (VIF)
X_with_constant = sm.add_constant(X)
vif_data = pd.DataFrame()
vif_data['Feature'] = X.columns
vif_data['VIF'] = [variance_inflation_factor(X_with_constant.values, i+1) for i in range(len(X.columns))]

# 3. Cross-Validation and Model Validation
# Perform cross-validation
cv_scores = cross_val_score(rf, X, y, cv=5)

# 4. Residual Analysis
# Calculate residuals
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)
residuals = y_test - y_pred

# Plot residuals
plt.figure(figsize=(10, 6))
sns.histplot(residuals, kde=True)
plt.title('Residuals Distribution')
plt.xlabel('Residuals')
plt.ylabel('Frequency')
plt.tight_layout()
plt.savefig('residuals_distribution.png')
plt.close()

print("Statistical Hypothesis Testing (Chi-square test):")
print("Chi2 Statistic:", chi2)
print("p-value:", p)

print("\
Model Assumptions Validation (VIF):")
print(vif_data)

print("\
Cross-Validation Scores:")
print(cv_scores)
print("Mean CV Score:", np.mean(cv_scores))

# Display the residuals distribution plot
Image('residuals_distribution.png')

from sklearn.model_selection import GridSearchCV
from xgboost import XGBClassifier

# Define the parameter grid for XGBoost
xgb_param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.2],
    'subsample': [0.7, 0.8, 1.0]
}

# Initialize XGBoost model
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)

# Perform Grid Search
xgb_grid_search = GridSearchCV(estimator=xgb_model, param_grid=xgb_param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=2)
xgb_grid_search.fit(X_train, y_train)

# Best parameters and best score
print("Best Parameters for XGBoost:", xgb_grid_search.best_params_)
print("Best XGBoost Score:", xgb_grid_search.best_score_)

from sklearn.model_selection import GridSearchCV
from lightgbm import LGBMClassifier

# Define the parameter grid for LightGBM
lgb_param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [-1, 5, 10],
    'learning_rate': [0.01, 0.1, 0.2],
    'num_leaves': [31, 50, 70]
}

# Initialize LightGBM model
lgb_model = LGBMClassifier(random_state=42)

# Perform Grid Search
lgb_grid_search = GridSearchCV(estimator=lgb_model, param_grid=lgb_param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=2)
lgb_grid_search.fit(X_train, y_train)

# Best parameters and best score
print("Best Parameters for LightGBM:", lgb_grid_search.best_params_)
print("Best LightGBM Score:", lgb_grid_search.best_score_)

from catboost import CatBoostClassifier
from sklearn.model_selection import GridSearchCV

# Define the parameter grid for CatBoost
cat_param_grid = {
    'iterations': [100, 200, 300],
    'depth': [4, 6, 8],
    'learning_rate': [0.01, 0.1, 0.2],
    'l2_leaf_reg': [1, 3, 5]
}

# Initialize CatBoost model
cat_model = CatBoostClassifier(verbose=0, random_state=42)

# Perform Grid Search
cat_grid_search = GridSearchCV(estimator=cat_model, param_grid=cat_param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=2)
cat_grid_search.fit(X_train, y_train)

# Best parameters and best score
print("Best Parameters for CatBoost:", cat_grid_search.best_params_)
print("Best CatBoost Score:", cat_grid_search.best_score_)

# Install catboost if not already installed
!pip install catboost

# Import libraries
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.metrics import accuracy_score, classification_report

# Initialize models
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
lgb_model = LGBMClassifier(random_state=42)
cat_model = CatBoostClassifier(verbose=0, random_state=42)

# Fit and evaluate XGBoost
xgb_model.fit(X_train, y_train)
xgb_preds = xgb_model.predict(X_test)
xgb_accuracy = accuracy_score(y_test, xgb_preds)
print("XGBoost Accuracy:", xgb_accuracy)
print(classification_report(y_test, xgb_preds))

# Fit and evaluate LightGBM
lgb_model.fit(X_train, y_train)
lgb_preds = lgb_model.predict(X_test)
lgb_accuracy = accuracy_score(y_test, lgb_preds)
print("LightGBM Accuracy:", lgb_accuracy)
print(classification_report(y_test, lgb_preds))

# Fit and evaluate CatBoost
cat_model.fit(X_train, y_train)
cat_preds = cat_model.predict(X_test)
cat_accuracy = accuracy_score(y_test, cat_preds)
print("CatBoost Accuracy:", cat_accuracy)
print(classification_report(y_test, cat_preds))

# Import necessary libraries
import pandas as pd
import numpy as np

# For data preprocessing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer

# For model training and evaluation
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import GridSearchCV

# Machine Learning Models
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier

# For ignoring warnings
import warnings
warnings.filterwarnings('ignore')

# 1. Load the Data
# Replace 'loan-train.csv' and 'loan-test.csv' with the correct paths if necessary
train_df = pd.read_csv('loan-train.csv')
test_df = pd.read_csv('loan-test.csv')

# Display the first few rows of the training data
print("Training Data Preview:")
print(train_df.head())

print("\nTesting Data Preview:")
print(test_df.head())

# 2. Data Preprocessing

# Combine train and test data for consistent preprocessing
test_df['Loan_Status'] = np.nan  # Add target column to test data for concatenation
combined = pd.concat([train_df, test_df], sort=False).reset_index(drop=True)

# Identify categorical and numerical columns
categorical_cols = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area']
numerical_cols = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']

# Handle missing values
# For numerical features, we'll use median imputation
num_imputer = SimpleImputer(strategy='median')
combined[numerical_cols] = num_imputer.fit_transform(combined[numerical_cols])

# For categorical features, we'll use mode imputation
cat_imputer = SimpleImputer(strategy='most_frequent')
combined[categorical_cols] = cat_imputer.fit_transform(combined[categorical_cols])

# Feature Engineering: Create new features if necessary
# Example: Loan-to-Income Ratio
combined['TotalIncome'] = combined['ApplicantIncome'] + combined['CoapplicantIncome']
combined['LoanIncomeRatio'] = combined['LoanAmount'] / combined['TotalIncome']

# Encoding categorical variables
# Using OneHotEncoder for nominal categorical variables
combined = pd.get_dummies(combined, columns=categorical_cols, drop_first=True)

# Log transformation for skewed numerical features
combined['ApplicantIncome'] = np.log1p(combined['ApplicantIncome'])
combined['CoapplicantIncome'] = np.log1p(combined['CoapplicantIncome'])
combined['LoanAmount'] = np.log1p(combined['LoanAmount'])

# Scaling numerical features
scaler = StandardScaler()
scaled_features = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History', 'TotalIncome', 'LoanIncomeRatio']
combined[scaled_features] = scaler.fit_transform(combined[scaled_features])

# Split the combined data back into train and test sets
train_processed = combined[combined['Loan_Status'].notnull()].copy()
test_processed = combined[combined['Loan_Status'].isnull()].copy()

# Drop unnecessary columns
train_processed.drop(['Loan_ID', 'Loan_Status'], axis=1, inplace=True)
test_processed.drop(['Loan_ID', 'Loan_Status'], axis=1, inplace=True)

# Encode target variable
label_encoder = LabelEncoder()
y_train = label_encoder.fit_transform(train_df['Loan_Status'])  # Assuming 'Y' and 'N'

X_train = train_processed
X_test = test_processed

# Display shapes
print("\nShapes:")
print("X_train:", X_train.shape)
print("y_train:", y_train.shape)
print("X_test:", X_test.shape)

# 3. Hyperparameter Tuning

# Function to perform Grid Search
def perform_grid_search(model, param_grid, X, y):
    grid_search = GridSearchCV(estimator=model,
                               param_grid=param_grid,
                               cv=3,
                               scoring='accuracy',
                               n_jobs=-1,
                               verbose=2)
    grid_search.fit(X, y)
    print(f"Best Parameters for {model.__class__.__name__}: {grid_search.best_params_}")
    print(f"Best {model.__class__.__name__} Score: {grid_search.best_score_}\n")
    return grid_search.best_estimator_

# 3.1 Hyperparameter Tuning for XGBoost
print("Tuning XGBoost...")
xgb_param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.2],
    'subsample': [0.7, 0.8, 1.0],
    'colsample_bytree': [0.7, 0.8, 1.0]
}

xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
best_xgb = perform_grid_search(xgb_model, xgb_param_grid, X_train, y_train)

# 3.2 Hyperparameter Tuning for LightGBM
print("Tuning LightGBM...")
lgb_param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [-1, 5, 10],
    'learning_rate': [0.01, 0.1, 0.2],
    'num_leaves': [31, 50, 70],
    'subsample': [0.7, 0.8, 1.0]
}

lgb_model = LGBMClassifier(random_state=42)
best_lgb = perform_grid_search(lgb_model, lgb_param_grid, X_train, y_train)

# 3.3 Hyperparameter Tuning for CatBoost
print("Tuning CatBoost...")
cat_param_grid = {
    'iterations': [100, 200, 300],
    'depth': [4, 6, 8],
    'learning_rate': [0.01, 0.1, 0.2],
    'l2_leaf_reg': [1, 3, 5],
    'border_count': [32, 64, 128]
}

cat_model = CatBoostClassifier(verbose=0, random_state=42)
best_cat = perform_grid_search(cat_model, cat_param_grid, X_train, y_train)

# 4. Model Evaluation

# Function to evaluate model
def evaluate_model(model, X, y, model_name):
    preds = model.predict(X)
    acc = accuracy_score(y, preds)
    print(f"{model_name} Accuracy: {acc}")
    print(f"{model_name} Classification Report:")
    print(classification_report(y, preds))
    print(f"{model_name} Confusion Matrix:")
    print(confusion_matrix(y, preds))
    print("\n")

# Evaluate XGBoost
print("Evaluating XGBoost on Training Data...")
evaluate_model(best_xgb, X_train, y_train, "XGBoost")

# Evaluate LightGBM
print("Evaluating LightGBM on Training Data...")
evaluate_model(best_lgb, X_train, y_train, "LightGBM")

# Evaluate CatBoost
print("Evaluating CatBoost on Training Data...")
evaluate_model(best_cat, X_train, y_train, "CatBoost")

# 5. Make Predictions on Test Set

# Assuming you want to generate predictions for the test set
# Note: Since the test set doesn't have 'Loan_Status', you might need to handle it accordingly
print("Making Predictions on Test Data...")
test_preds_xgb = best_xgb.predict(X_test)
test_preds_lgb = best_lgb.predict(X_test)
test_preds_cat = best_cat.predict(X_test)

# For ensemble predictions, you could average the probabilities or use voting
# Here's an example using majority voting
from scipy.stats import mode

# Get predictions from each model
test_preds = np.vstack([test_preds_xgb, test_preds_lgb, test_preds_cat]).T

# Apply majority voting
final_test_preds = mode(test_preds, axis=1)[0].flatten()

# Convert numerical predictions back to original labels if necessary
final_test_preds_labels = label_encoder.inverse_transform(final_test_preds)

# Prepare submission or output
# For demonstration, we'll just print the first few predictions
print("\nSample Predictions on Test Data:")
print(final_test_preds_labels[:10])

# Optionally, save the predictions to a CSV file
# submission = pd.DataFrame({
#     'Loan_ID': test_df['Loan_ID'],
#     'Loan_Status': final_test_preds_labels
# })
# submission.to_csv('loan_eligibility_predictions.csv', index=False)

import matplotlib.pyplot as plt
import seaborn as sns

# Feature importance for XGBoost
xgb_importance = best_xgb.feature_importances_
xgb_features = X_train.columns
xgb_imp_df = pd.DataFrame({'Feature': xgb_features, 'Importance': xgb_importance})
xgb_imp_df = xgb_imp_df.sort_values(by='Importance', ascending=False)

plt.figure(figsize=(10, 8))
sns.barplot(x='Importance', y='Feature', data=xgb_imp_df.head(10))
plt.title('Top 10 Feature Importances in XGBoost')
plt.show()

"""cross- validation and model validation"""

from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression

# Define the base learners with the best estimators
base_learners = [
    ('xgb', best_xgb),
    ('lgb', best_lgb),
    ('cat', best_cat)
]

# Define the meta-learner
meta_learner = LogisticRegression()

# Create the stacking model
stacking_model = StackingClassifier(estimators=base_learners, final_estimator=meta_learner, cv=3)

# Train the stacking model on the training data
stacking_model.fit(X_train, y_train)

# Evaluate the stacking model on the training data
print("Evaluating Stacking Model on Training Data...")
evaluate_model(stacking_model, X_train, y_train, "Stacking Model")

# Make predictions on the test set using the stacking model
stacking_test_preds = stacking_model.predict(X_test)

# Convert numerical predictions back to original labels if necessary
stacking_test_preds_labels = label_encoder.inverse_transform(stacking_test_preds)

# Display sample predictions
print("\nSample Predictions on Test Data (Stacking):")
print(stacking_test_preds_labels[:10])

# Optionally, save the stacking predictions to a CSV file
# stacking_submission = pd.DataFrame({
#     'Loan_ID': test_df['Loan_ID'],
#     'Loan_Status': stacking_test_preds_labels
# })
# stacking_submission.to_csv('stacking_loan_eligibility_predictions.csv', index=False)

!pip install flask flask-ngrok

from flask import Flask, request, jsonify
from flask_ngrok import run_with_ngrok

app = Flask(__name__)
run_with_ngrok(app)  # Start ngrok when app is run

@app.route('/predict', methods=['POST'])
def predict():
    # Load user input from request
    data = request.get_json()

    # Extract features from JSON data
    # Apply preprocessing as done in your model training, like encoding and scaling
    # Make sure to convert categorical inputs to appropriate numerical values

    # Use your trained model for prediction
    # pred = your_model.predict(processed_data)
    # prediction = 'Approved' if pred[0] == 1 else 'Not Approved'

    # For demonstration, Iâ€™ll use a placeholder prediction
    prediction = "Approved"  # Replace with model prediction

    return jsonify({'Loan_Status': prediction})

if __name__ == '__main__':
    app.run()